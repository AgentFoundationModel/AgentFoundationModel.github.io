#+title: An Interactive Agent Foundation Model
#+author: Bidipta Sarkar
#+email: bidiptas@stanford.edu
#+description: An Interactive Agent Foundation Model
#+KEYWORDS: homepage, website, research, AI
#+LANGUAGE:  en
#+OPTIONS: email:t toc:nil num:nil html-postamble:nil html-style:nil title:nil \n:t H:3
#+startup: inlineimages
#+EXPORT_FILE_NAME: index

#+PROPERTY:  header-args :eval never-export

#+INCLUDE: "header.org"


@@html:<div class="row"><h2 class="col-md-12 text-center"><strong><font size="+4r">@@  An Interactive Agent Foundation Model @@html:</font></strong></h2></div>@@


#+html: <div class="row"> <div class="col-md-12 text-center">
#+attr_html: :class list-inline
- Zane Durante
- Bidipta Sarkar
- Ran Gong
- Rohan Taori
- Yusuke Noda
- Paul Tang
- Ehsan Adeli
- Shrinidhi Kowshika Lakshmikanth
- Kevin Schulman
- Arnold Milstein
- Demetri Terzopoulos
- Ade Famoti
- Noboru Kuno
- Ashley Llorens
- Hoi Vo
- Katsu Ikeuchi
- Li Fei-Fei
- Jianfeng Gao
- Naoki Wake
- Qiuyuan Huang


# @@html:<br><a href="https://stanford.edu"><image src="img/stanford_logo.png" height="55px"> </a><a href="http://iliad.stanford.edu"> <image src="img/iliad.png" height="40px"> </a><br>@@
#+html: </div> </div>


#+html: <div class="row"> <div class="col-md-12 text-center">
#+attr_html: :class list-inline
- @@html:<image src="img/msr_logo.gif" height="55px">@@
- @@html:<image src="img/stanford_logo.png" height="48px">@@
- @@html:<image src="img/ucla_logo.png" height="48px">@@
#+html: </div> </div>

#+html: <div class="row"> <div class="col-md-4 col-md-offset-4 text-center">
#+attr_html: :class nav nav-pills nav-justified
- @@html:<a href="pdfs/paper.pdf"><image src="img/paper.png" height="60px"><h4><strong>Paper</strong></h4></a>@@
- @@html:<image src="img/huggingface.svg" height="60px"><h4><strong>Model (Coming Soon!)</strong></h4>@@
# - @@html:<a href="https://youtu.be/wm4f0sdKIUA"><image src="img/youtube_icon.png" height="60px"><h4><strong>Video</strong></h4></a>@@
# - @@html:<a href="https://github.com/Stanford-ILIAD/Diverse-Conventions"><image src="img/GitHub-Mark.png" height="60px"><h4><strong>Code</strong></h4></a>@@
#+html: </div></div>

#+html: <div class="row"> <div class="col-md-8 col-md-offset-2">

# #+BEGIN_export html

# <div style="position:relative;padding-top:56.25%;">
#               <!-- <iframe width="560" height="315" src="https://www.youtube.com/embed/UuKAp9a6wMs" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe> -->
# 	      <iframe src="https://www.youtube.com/embed/wm4f0sdKIUA?si=ZCvJyvJLZsCa3FjH" width="560" height="315" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
#             </div>
# #+END_export

* 

** Abstract

The development of artificial intelligence systems is transitioning from creating static, task-specific models to dynamic, agent-based systems capable of performing well in a wide range of applications. We propose an Interactive Agent Foundation Model that uses a novel multi-task agent training paradigm for training AI agents across a wide range of domains, datasets, and tasks. Our training paradigm unifies diverse pre-training strategies, including visual masked auto-encoders, language modeling, and next-action prediction, enabling a versatile and adaptable AI framework. We demonstrate the performance of our framework across three separate domains -- Robotics, Gaming AI, and Healthcare. Our model demonstrates its ability to generate meaningful and contextually relevant outputs in each area. The strength of our approach lies in its generality, leveraging a variety of data sources such as robotics sequences, gameplay data, large-scale video datasets, and textual information for effective multimodal and multi-task learning. Our approach provides a promising avenue for developing generalist, action-taking, multimodal systems.

** Robotics Examples

We pre-train our model on the CALVIN and Language Table Datasets. Below we show example successful rollouts of our policy in randomized initial conditions in both environments.

CALVIN:

** 
  :PROPERTIES:
  :html_container: div
  :html_container_class: irow
  :END:

*** Open Drawer
  :PROPERTIES:
  :html_container: div
  :html_container_class: column
  :END:

  @@html:<video width="100%" controls> <source src="AVL_Example_Videos/open_drawer_1706692234.1586585.mp4" type="video/mp4"> </video>@@


*** Move Slider Right
  :PROPERTIES:
  :html_container: div
  :html_container_class: column
  :END:

  @@html:<video width="100%" controls> <source src="AVL_Example_Videos/move_slider_right_1706691956.3111706.mp4" type="video/mp4"> </video>@@


*** Lift Red Block
  :PROPERTIES:
  :html_container: div
  :html_container_class: column
  :END:

  @@html:<video width="100%" controls> <source src="AVL_Example_Videos/lift_red_block_slider_1706690975.078765.mp4" type="video/mp4"> </video>@@


*** Close Drawer
  :PROPERTIES:
  :html_container: div
  :html_container_class: column
  :END:

  @@html:<video width="100%" controls> <source src="AVL_Example_Videos/close_drawer_1706690941.4207315.mp4" type="video/mp4"> </video>@@

  
# *** Move Slider Left
#   :PROPERTIES:
#   :html_container: div
#   :html_container_class: column
#   :END:

#   @@html:<video width="50%" controls> <source src="AVL_Example_Videos/move_slider_left_1706691291.7631042.mp4" type="video/mp4"> </video>@@


** 

Language Table:

** 
  :PROPERTIES:
  :html_container: div
  :html_container_class: irow
  :END:

*** Block to Absolute Location
  :PROPERTIES:
  :html_container: div
  :html_container_class: column
  :END:

  @@html:<video width="100%" controls> <source src="AVL_Example_Videos/blocktoabsolutelocation_41_success.mp4" type="video/mp4"> </video>@@


*** Block to Block
  :PROPERTIES:
  :html_container: div
  :html_container_class: column
  :END:

  @@html:<video width="100%" controls> <source src="AVL_Example_Videos/blocktoblock_47_success.mp4" type="video/mp4"> </video>@@

*** Block to Relative Location
  :PROPERTIES:
  :html_container: div
  :html_container_class: column
  :END:

  @@html:<video width="100%" controls> <source src="AVL_Example_Videos/blocktorelativelocation_27_success.mp4" type="video/mp4"> </video>@@

  
*** Separate Blocks
  :PROPERTIES:
  :html_container: div
  :html_container_class: column
  :END:

  @@html:<video width="100%" controls> <source src="AVL_Example_Videos/separate_27_success.mp4" type="video/mp4"> </video>@@


# *** Block Relative to Another Block
#   :PROPERTIES:
#   :html_container: div
#   :html_container_class: column
#   :END:

#   @@html:<video width="50%" controls> <source src="AVL_Example_Videos/blocktoblockrelativelocation_20_success.mp4" type="video/mp4"> </video>@@


  

** Gaming Examples

We also pre-train our model on datasets of Minecraft and Bleeding Edge videos annotated with actions. Below we show example predicted actions from our policy compared to ground truth actions taken by a player following specific instructions.


Minecraft Task: The player is using an iron sword to attack and kill pigs in a forest ...


** 
  :PROPERTIES:
  :html_container: div
  :html_container_class: irow
  :END:

*** Video
  :PROPERTIES:
  :html_container: div
  :html_container_class: column
  :END:

  @@html:<video width="100%" controls> <source src="AVL_Example_Videos/minecraft_15/minecraft.mp4" type="video/mp4"> </video>@@


*** Actions
  :PROPERTIES:
  :html_container: div
  :html_container_class: column
  :END:

  
  | Ground Truth | Predicted Action |
  |--------------+------------------|
  |--------------+------------------|
  | [CAMERAX7]   | [CAMERAX4]       |
  | [CAMERAY22]  | [CAMERAY9]       |
  |--------------+------------------|
  | [CAMERAX0]   | [CAMERAX4]       |
  | [CAMERAY2]   | [CAMERAY23]      |
  |--------------+------------------|
  | [attack]     | [attack]         |
  | [CAMERAX-1]  |                  |
  | [CAMERAY2]   |                  |
  |--------------+------------------|
  | [attack]     | [attack]         |
  |--------------+------------------|
  | [attack]     | [attack]         |

** 

Bleeding Edge Task: The player is controlling a red robot ... fighting other characters ...


** 
  :PROPERTIES:
  :html_container: div
  :html_container_class: irow
  :END:

*** Video
  :PROPERTIES:
  :html_container: div
  :html_container_class: column
  :END:

  @@html:<video width="100%" controls> <source src="AVL_Example_Videos/be_88/be.mp4" type="video/mp4"> </video>@@

*** Actions
  :PROPERTIES:
  :html_container: div
  :html_container_class: column
  :END:

  | Ground Truth                            | Predicted Action                        |
  |-----------------------------------------+-----------------------------------------|
  |-----------------------------------------+-----------------------------------------|
  | [lockon][meleeattack] [lrot159] [lmag4] | [specialability2] [lrot216] [lmag4]     |
  |-----------------------------------------+-----------------------------------------|
  | [lockon][meleeattack] [lrot159] [lmag4] | [lockon][meleeattack] [lrot159] [lmag4] |
  |-----------------------------------------+-----------------------------------------|
  | [lockon][meleeattack] [lrot159] [lmag4] | [lockon][meleeattack] [lrot159] [lmag4] |
  |-----------------------------------------+-----------------------------------------|
  | [lockon][meleeattack] [lrot160] [lmag4] | [lockon][meleeattack] [lrot162] [lmag4] |
  |-----------------------------------------+-----------------------------------------|

** Healthcare Examples

We fine-tuned our model on healthcare data and find that pre-training on robotics and gaming datasets provides some positive transfer for predicting actions. Below we show examples of our fine-tuned model performing various tasks in healthcare.


** 
/Video Captioning/

** 
  :PROPERTIES:
  :html_container: div
  :html_container_class: irow
  :END:

*** Video
  :PROPERTIES:
  :html_container: div
  :html_container_class: column
  :END:

  # @@html:<video width="100%" controls> <source src="AVL_Example_Videos/healthcare/healthcare1.mpf_frame_0.png" type="video/mp4"> </video>@@
  @@html:<image src="AVL_Example_Videos/healthcare/healthcare1.mp4_frame0.png" width="100%">@@


*** Actions
  :PROPERTIES:
  :html_container: div
  :html_container_class: column
  :END:

  The patient is awake and calm. The patient is cooperative. The patient is alert.


** 
/Video Question Answering/

** 
  :PROPERTIES:
  :html_container: div
  :html_container_class: irow
  :END:

*** Video
  :PROPERTIES:
  :html_container: div
  :html_container_class: column
  :END:

  # @@html:<video width="100%" controls> <source src="AVL_Example_Videos/healthcare/healthcare3.mp4_frame0.png" type="video/mp4"> </video>@@
  @@html:<image src="AVL_Example_Videos/healthcare/healthcare3.mp4_frame0.png" width="100%">@@


*** Actions
  :PROPERTIES:
  :html_container: div
  :html_container_class: column
  :END:

  Q: Where is the patient? A: patient is in deep sedation. The patient likely requires assistance.




** 
/Action recognition (RASS)/

** 
  :PROPERTIES:
  :html_container: div
  :html_container_class: irow
  :END:

*** Video
  :PROPERTIES:
  :html_container: div
  :html_container_class: column
  :END:

  # @@html:<video width="100%" controls> <source src="AVL_Example_Videos/healthcare/healthcare3.mp4_frame0.png" type="video/mp4"> </video>@@
  @@html:<image src="AVL_Example_Videos/healthcare/frame_0.jpg" width="100%">@@


*** Actions
  :PROPERTIES:
  :html_container: div
  :html_container_class: column
  :END:

  0 - Alert and calm

#+html: </div>

#+html:</div></div></div>
# #+BEGIN_export html
# <div class="row">
# 	  <div class="col-md-8 col-md-offset-2">
#             <h3>
#               Citation
#             </h3>
#             <div class="form-group col-md-10 col-md-offset-1">
#               <textarea id="bibtex" class="form-control" readonly>@inproceedings{sarkar2023diverse,
# 	title={Diverse Conventions for Human-{AI} Collaboration},
# 	author={Bidipta Sarkar and Andy Shih and Dorsa Sadigh},
# 	booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
# 	year={2023}
# }</textarea>
#             </div>
# 	  </div>
	  
# 	</div>
# #+END_export
#+BEGIN_export html
	<div class="row">
	  <div class="col-md-8 col-md-offset-2">
            <!-- <h3> -->
              <!--     Acknowledgements -->
              <!-- </h3> -->
            <p class="text-justify">
              <br><br>
              The website template was borrowed from <a href="http://jonbarron.info/">Jon Barron</a>
            </p>
	  </div>
	</div>
#+END_export

# Local Variables:
# eval: (add-hook 'after-save-hook (lambda nil (when (y-or-n-p "Tangle?") (org-html-export-to-html))) nil t)
# End:
